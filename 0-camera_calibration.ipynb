{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a5add4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "IN_COLAB = 'google.colab' in sys.modules\n",
    "\n",
    "data_path = \"./\"\n",
    "if IN_COLAB:\n",
    "    data_path = '/content/Prague_ml_data'\n",
    "    if os.path.exists(data_path):\n",
    "        print(\"Prague_ml_data already exists\")\n",
    "    else:\n",
    "        ! git clone https://github.com/VarunBurde/Prague_ml_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2489286",
   "metadata": {},
   "source": [
    "### Image formation \n",
    "We know the properties of light and optics, and how rays travel from the light source to a screen to form an image. A camera works on the same principle, but instead of a screen, it captures the light rays on a sensor and transforms them into RGB pixel values.\n",
    "\n",
    "\n",
    "![Image formation in pinhole camera](visulization_data/Pinhole-camera.png)\n",
    "\n",
    "\n",
    "Light rays from a scene travel and converge at the image plane, where a sharp image is formed. The optical center is the point from which these rays appear to diverge. The focal length is the distance from this point to the image plane, affecting how the scene is scaled in the image\n",
    "\n",
    "\n",
    "### Camera Intrinsics\n",
    "\n",
    "The camera intrinsic matrix (K) describes how 3D points in camera coordinates are projected onto the 2D image plane:\n",
    "\n",
    "$$K = \\begin{bmatrix}\n",
    "f_x & 0 & c_x \\\\\n",
    "0 & f_y & c_y \\\\\n",
    "0 & 0 & 1\n",
    "\\end{bmatrix}$$\n",
    "\n",
    "Where:\n",
    "- $f_x$, $f_y$: Focal length in pixels (in x and y directions)\n",
    "- $c_x$, $c_y$: Principal point coordinates (optical center on the image plane)\n",
    "\n",
    "This matrix encapsulates the internal optical characteristics of the camera, independent of the camera's position and orientation in the world.\n",
    "\n",
    "For more information, see: [Camera Parameters in Computer Vision](https://towardsdatascience.com/what-are-intrinsic-and-extrinsic-camera-parameters-in-computer-vision-7071b72fb8ec/)\n",
    "\n",
    "### Camera Extrinsics\n",
    "\n",
    "![Image Plane](visulization_data/intrnsics.png)\n",
    "\n",
    "When a 3D point at coordinates **(x, y, z)** in Cartesian space is projected onto the 2D image plane, it undergoes a transformation from world space to image (pixel) space **(u, v)**. This transformation involves a rotation **R** and translation **T**, and is represented by the **projection matrix**:\n",
    "$$\\begin{bmatrix} u \\\\ v \\\\ 1 \\end{bmatrix} = P \\begin{bmatrix} x \\\\ y \\\\ z \\\\ 1 \\end{bmatrix} = K[R|T] \\begin{bmatrix} x \\\\ y \\\\ z \\\\ 1 \\end{bmatrix}$$\n",
    "\n",
    "Where:\n",
    "\n",
    "- **K** is the intrinsic camera matrix (describing internal parameters),\n",
    "- **R** is the rotation matrix,\n",
    "- **T** is the translation vector.\n",
    "\n",
    "In theory, this allows us to map 3D world coordinates to 2D image coordinates. However, the inverse mapping—from **(u, v)** back to **(x, y, z)**—is not directly possible because the projection is a many-to-one transformation. This loss of depth information makes it non-symmetric and inherently **ill-posed**, which is one of the core challenges in 3D computer vision and depth reconstruction.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0df79775",
   "metadata": {},
   "source": [
    "### Lens and Distortion\n",
    "\n",
    "### Understanding Optical Aberrations\n",
    "\n",
    "Lens distortions are optical aberrations that cause straight lines in the real world to appear curved in captured images. These distortions are not defects but natural consequences of the physical properties and design of camera lenses.\n",
    "\n",
    "When light passes through a lens, its path can be altered in ways that don't perfectly preserve the straight-line geometry of the original scene. These aberrations become particularly noticeable in images containing straight lines, especially near the edges of the frame.\n",
    "\n",
    "![Lens Distortion Example](visulization_data/distorted_image.jpg)\n",
    "## Do you see the straight lines? Do you think the image is distorted or does the dancing house windows not follow straight lines?\n",
    "\n",
    "### Key Points:\n",
    "\n",
    "- **Physical Cause**: Results from the geometric properties of lens elements\n",
    "- **Impact**: Affects measurements, geometric accuracy, and visual aesthetics\n",
    "- **Variability**: Different lens types exhibit different characteristic distortions\n",
    "- **Correctability**: Can be mathematically modeled and corrected in post-processing\n",
    "\n",
    "### Further Reading\n",
    "\n",
    "- [Types of Distortion and Measurement Methods](https://www.image-engineering.de/library/image-quality/factors/1062-distortion)\n",
    "- [Camera Visualization and Calibration](https://docs.nerf.studio/nerfology/model_components/visualize_cameras.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d33d683f",
   "metadata": {},
   "source": [
    "## Try to play with distortion values and see if you ever saw such distortion before\n",
    "\n",
    "### Types of Lens Distortions\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a147d58b",
   "metadata": {},
   "source": [
    "### 1. Barrel Distortion\n",
    "\n",
    "**Causes:**\n",
    "- Occurs when magnification decreases as you move away from the optical center\n",
    "- Common in wide-angle lenses\n",
    "- Lines appear to bow outward like a barrel\n",
    "\n",
    "**Correction Method:**\n",
    "- Can be modeled using radial distortion coefficients (k1, k2, k3)\n",
    "- Corrected using the equation: x_corrected = x(1 + k1*r² + k2*r⁴ + k3*r⁶)\n",
    "\n",
    "![Image Description](visulization_data/barrel_dist.png)\n",
    "\n",
    "**Calibration Views Needed:**\n",
    "- Straight-on (front-facing) views with checkerboard pattern\n",
    "- Close-up views particularly effective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61229f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of barrel distortion visualization\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def create_barrel_distortion(img, k1=-0.3):\n",
    "    \"\"\"Apply synthetic barrel distortion to an image\"\"\"\n",
    "    h, w = img.shape[:2]\n",
    "    # Create camera matrix\n",
    "    cam_mat = np.array([[w, 0, w/2],\n",
    "                       [0, w, h/2],\n",
    "                       [0, 0, 1]])\n",
    "    \n",
    "    # Distortion coefficients [k1, k2, p1, p2, k3]\n",
    "    dist_coeffs = np.array([k1, 0, 0, 0, 0])\n",
    "    \n",
    "    # Apply distortion\n",
    "    distorted = cv2.undistort(img, cam_mat, -dist_coeffs)  # Negative to create distortion\n",
    "    return distorted\n",
    "\n",
    "# Example usage (commented out until we have an image)\n",
    "img_path = os.path.join(data_path, 'visulization_data', 'sample_grid.png')  # Replace with your image path\n",
    "img = cv2.imread(img_path)\n",
    "if img is not None:\n",
    "    barrel_img = create_barrel_distortion(img)\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(12, 6))\n",
    "    axes[0].imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "    axes[0].set_title('Original Image')\n",
    "    axes[1].imshow(cv2.cvtColor(barrel_img, cv2.COLOR_BGR2RGB))\n",
    "    axes[1].set_title('With Barrel Distortion')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e36ad694",
   "metadata": {},
   "source": [
    "## 2. Pincushion Distortion\n",
    "\n",
    "**Causes:**\n",
    "- Occurs when magnification increases as you move away from the optical center\n",
    "- Common in telephoto lenses\n",
    "- Lines curve inward like a pincushion\n",
    "\n",
    "**Correction Method:**\n",
    "- Uses the same radial distortion model as barrel distortion but with opposite sign coefficients\n",
    "- Software correction algorithms in post-processing\n",
    "\n",
    "![Pincushion Distortion](visulization_data/pincu_dist.png)\n",
    "\n",
    "**Calibration Views Needed:**\n",
    "- Distant views of calibration pattern\n",
    "- Edge-of-frame views to capture maximum distortion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3f139b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of pincushion distortion visualization\n",
    "def create_pincushion_distortion(img, k1=0.3):\n",
    "    \"\"\"Apply synthetic pincushion distortion to an image\"\"\"\n",
    "    h, w = img.shape[:2]\n",
    "    # Create camera matrix\n",
    "    cam_mat = np.array([[w, 0, w/2],\n",
    "                       [0, w, h/2],\n",
    "                       [0, 0, 1]])\n",
    "    \n",
    "    # Distortion coefficients [k1, k2, p1, p2, k3]\n",
    "    dist_coeffs = np.array([k1, 0, 0, 0, 0])\n",
    "    \n",
    "    # Apply distortion\n",
    "    distorted = cv2.undistort(img, cam_mat, -dist_coeffs)  # Negative to create distortion\n",
    "    return distorted\n",
    "\n",
    "# Example usage (commented out until we have an image)\n",
    "img = cv2.imread(img_path)\n",
    "if img is not None:\n",
    "    pincushion_img = create_pincushion_distortion(img)\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(12, 6))\n",
    "    axes[0].imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "    axes[0].set_title('Original Image')\n",
    "    axes[1].imshow(cv2.cvtColor(pincushion_img, cv2.COLOR_BGR2RGB))\n",
    "    axes[1].set_title('With Pincushion Distortion')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1591dfdb",
   "metadata": {},
   "source": [
    "## 3. Mustache Distortion\n",
    "\n",
    "**Causes:**\n",
    "- Complex aberrations in lens design\n",
    "- Combination of barrel and pincushion distortions\n",
    "- Common in zoom lenses\n",
    "\n",
    "**Correction Method:**\n",
    "- Requires higher-order polynomial models\n",
    "- Often needs both radial and tangential distortion coefficients\n",
    "\n",
    "![Mustache Distortion](visulization_data/mustach_dist.jpg)\n",
    "\n",
    "**Calibration Views Needed:**\n",
    "- Angled views of calibration pattern\n",
    "- Multiple perspectives to capture transition between distortion types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ddadbbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of mustache distortion visualization\n",
    "def create_mustache_distortion(img, k1=-0.2, k2=0.2):\n",
    "    \"\"\"Apply synthetic mustache distortion to an image\"\"\"\n",
    "    h, w = img.shape[:2]\n",
    "    # Create camera matrix\n",
    "    cam_mat = np.array([[w, 0, w/2],\n",
    "                       [0, w, h/2],\n",
    "                       [0, 0, 1]])\n",
    "    \n",
    "    # Distortion coefficients [k1, k2, p1, p2, k3]\n",
    "    dist_coeffs = np.array([k1, k2, 0, 0, 0])\n",
    "    \n",
    "    # Apply distortion\n",
    "    distorted = cv2.undistort(img, cam_mat, -dist_coeffs)  # Negative to create distortion\n",
    "    return distorted\n",
    "\n",
    "# Example usage (commented out until we have an image)\n",
    "img = cv2.imread(img_path)\n",
    "if img is not None:\n",
    "    mustache_img = create_mustache_distortion(img)\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(12, 6))\n",
    "    axes[0].imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "    axes[0].set_title('Original Image')\n",
    "    axes[1].imshow(cv2.cvtColor(mustache_img, cv2.COLOR_BGR2RGB))\n",
    "    axes[1].set_title('With Mustache Distortion')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adf35dac",
   "metadata": {},
   "source": [
    "## 4. Tangential (Decentering) Distortion\n",
    "\n",
    "**Causes:**\n",
    "- Lens not perfectly aligned with camera sensor\n",
    "- Optical elements inside lens are misaligned\n",
    "- Creates asymmetrical distortion\n",
    "\n",
    "![Tangential (Decentering) Distortion](visulization_data/tang_dist_1.png)\n",
    "\n",
    "**Correction Method:**\n",
    "- Modeled using tangential distortion coefficients (p1, p2)\n",
    "- Correction equations:\n",
    "  - x_corrected = x + [2p1xy + p2(r² + 2x²)]\n",
    "  - y_corrected = y + [p1(r² + 2y²) + 2p2xy]\n",
    "\n",
    "![Tangential (Decentering) Distortion](visulization_data/tang_dist_2.png)\n",
    "\n",
    "**Calibration Views Needed:**\n",
    "- Tilted and rotated views of calibration pattern\n",
    "- Multiple orientations to detect asymmetries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51a75cdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of tangential distortion visualization\n",
    "def create_tangential_distortion(img, p1=0.0005, p2=0.0005):\n",
    "    \"\"\"Apply synthetic tangential distortion to an image\"\"\"\n",
    "    h, w = img.shape[:2]\n",
    "    # Create camera matrix\n",
    "    cam_mat = np.array([[w, 0, w/2],\n",
    "                       [0, w, h/2],\n",
    "                       [0, 0, 1]])\n",
    "    \n",
    "    # Distortion coefficients [k1, k2, p1, p2, k3]\n",
    "    dist_coeffs = np.array([0, 0, p1, p2, 0])\n",
    "    \n",
    "    # Apply distortion\n",
    "    distorted = cv2.undistort(img, cam_mat, -dist_coeffs)  # Negative to create distortion\n",
    "    return distorted\n",
    "\n",
    "# Example usage (commented out until we have an image)\n",
    "img = cv2.imread(img_path)\n",
    "if img is not None:\n",
    "    tangential_img = create_tangential_distortion(img)\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(12, 6))\n",
    "    axes[0].imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "    axes[0].set_title('Original Image')\n",
    "    axes[1].imshow(cv2.cvtColor(tangential_img, cv2.COLOR_BGR2RGB))\n",
    "    axes[1].set_title('With Tangential Distortion')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0a069c4",
   "metadata": {},
   "source": [
    "### Camera Calibration and Reprojection Error Calculation\n",
    "\n",
    "In this section, we'll perform camera calibration using checkerboard images and calculate the reprojection error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "146d6a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "\n",
    "def calibrate_camera(image_dir, checkerboard_size=(8, 5)):\n",
    "    \"\"\"Calibrate the camera and calculate reprojection error.\"\"\"\n",
    "    # Termination criteria for corner sub-pixel accuracy\n",
    "    criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 30, 0.001)\n",
    "\n",
    "    # Prepare object points (e.g., (0,0,0), (1,0,0), ..., (8,5,0))\n",
    "    objp = np.zeros((checkerboard_size[0] * checkerboard_size[1], 3), np.float32)\n",
    "    objp[:, :2] = np.mgrid[0:checkerboard_size[0], 0:checkerboard_size[1]].T.reshape(-1, 2)\n",
    "\n",
    "    # Arrays to store object points and image points\n",
    "    objpoints = []  # 3D points in real world space\n",
    "    imgpoints = []  # 2D points in image plane\n",
    "\n",
    "    # Load all images from the directory\n",
    "    # images = glob.glob(f\"{image_dir}/*.jpg\")\n",
    "    images = image_dir\n",
    "\n",
    "    for fname in images:\n",
    "        img = cv2.imread(fname)\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # Find the chessboard corners\n",
    "        ret, corners = cv2.findChessboardCorners(gray, checkerboard_size, None)\n",
    "\n",
    "        if ret:\n",
    "            objpoints.append(objp)\n",
    "            corners2 = cv2.cornerSubPix(gray, corners, (11, 11), (-1, -1), criteria)\n",
    "            imgpoints.append(corners2)\n",
    "\n",
    "    # Perform camera calibration\n",
    "    ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints, gray.shape[::-1], None, None)\n",
    "\n",
    "    # Calculate reprojection error\n",
    "    total_error = 0\n",
    "    for i in range(len(objpoints)):\n",
    "        imgpoints2, _ = cv2.projectPoints(objpoints[i], rvecs[i], tvecs[i], mtx, dist)\n",
    "        error = cv2.norm(imgpoints[i], imgpoints2, cv2.NORM_L2) / len(imgpoints2)\n",
    "        total_error += error\n",
    "\n",
    "    mean_error = total_error / len(objpoints)\n",
    "\n",
    "    return mtx, dist, mean_error, imgpoints, imgpoints2, rvecs, tvecs\n",
    "\n",
    "# Analyze distortion coefficients\n",
    "def analyze_distortion(dist_coeffs):\n",
    "    \"\"\"\n",
    "    Analyze distortion coefficients to determine the type of lens distortion.\n",
    "    \n",
    "    Args:\n",
    "        dist_coeffs: Array of distortion coefficients from camera calibration\n",
    "    \n",
    "    Returns:\n",
    "        str: Description of the dominant distortion type\n",
    "    \"\"\"\n",
    "    k1, k2, p1, p2, k3 = dist_coeffs.flatten()\n",
    "    \n",
    "    if k1 < 0 and abs(k1) > abs(k2):\n",
    "        return \"Barrel distortion is dominant (negative k1)\"\n",
    "    elif k1 > 0 and abs(k1) > abs(k2):\n",
    "        return \"Pincushion distortion is dominant (positive k1)\"\n",
    "    elif abs(p1) > 0.01 or abs(p2) > 0.01:\n",
    "        return \"Tangential distortion is present (p1 or p2 not close to zero)\"\n",
    "    else:\n",
    "        return \"No significant distortion detected\"\n",
    "\n",
    "\n",
    "# Example usage\n",
    "if IN_COLAB:\n",
    "  image_directory = \"/content/Prague_ml_data/dataset/chessboard\"\n",
    "else:\n",
    "  image_directory = \"dataset/chessboard\"\n",
    "straight_on_images = [os.path.join(image_directory, \"straight_on_1.jpg\"),\n",
    "                        os.path.join(image_directory, \"straight_on_2.jpg\"),\n",
    "                        os.path.join(image_directory, \"straight_on_3.jpg\"),\n",
    "                        ]\n",
    "\n",
    "intrinsic_matrix, distortion_coeffs, reprojection_error, imgpoints, imgpoints2, rvecs, tvecs = calibrate_camera(straight_on_images)\n",
    "\n",
    "print(\"\\n--- Calibration Results for Straight-On Images ---\")\n",
    "print(f\"Reprojection Error: {reprojection_error:.4f}\")\n",
    "print(f\"Distortion Coefficients: {distortion_coeffs}\")\n",
    "print(f\"Distortion Analysis: {analyze_distortion(distortion_coeffs)}\")\n",
    "\n",
    "end_of_the_frame_images = [os.path.join(image_directory, \"end_of_the_frame_1.jpg\"),\n",
    "                        os.path.join(image_directory, \"end_of_the_frame_2.jpg\"),\n",
    "                        os.path.join(image_directory, \"end_of_the_frame_3.jpg\"),\n",
    "                        os.path.join(image_directory, \"end_of_the_frame_4.jpg\"),\n",
    "                        ]\n",
    "\n",
    "intrinsic_matrix, distortion_coeffs, reprojection_error, imgpoints, imgpoints2, rvecs, tvecs = calibrate_camera(end_of_the_frame_images)\n",
    "\n",
    "print(\"\\n--- Calibration Results for End-of-the-Frame Images ---\")\n",
    "print(f\"Reprojection Error: {reprojection_error:.4f}\")\n",
    "print(f\"Distortion Coefficients: {distortion_coeffs}\")\n",
    "print(f\"Distortion Analysis: {analyze_distortion(distortion_coeffs)}\")\n",
    "\n",
    "tilted_and_rotated_images = [os.path.join(image_directory, \"tilted_and_rotated_1.jpg\"),\n",
    "                        os.path.join(image_directory, \"tilted_and_rotated_2.jpg\"),\n",
    "                        os.path.join(image_directory, \"tilted_and_rotated_3.jpg\"),\n",
    "                        os.path.join(image_directory, \"tilted_and_rotated_4.jpg\"),\n",
    "                        os.path.join(image_directory, \"tilted_and_rotated_5.jpg\"),\n",
    "                        ]\n",
    "\n",
    "intrinsic_matrix, distortion_coeffs, reprojection_error, imgpoints, imgpoints2, rvecs, tvecs = calibrate_camera(tilted_and_rotated_images)\n",
    "\n",
    "print(\"\\n--- Calibration Results for Tilted and Rotated Images ---\")\n",
    "print(f\"Reprojection Error: {reprojection_error:.4f}\")\n",
    "print(f\"Distortion Coefficients: {distortion_coeffs}\")\n",
    "print(f\"Distortion Analysis: {analyze_distortion(distortion_coeffs)}\")\n",
    "\n",
    "angled_view_images = [os.path.join(image_directory, \"angled_view_1.jpg\"),\n",
    "                        os.path.join(image_directory, \"angled_view_2.jpg\"),\n",
    "                        ]\n",
    "\n",
    "intrinsic_matrix, distortion_coeffs, reprojection_error, imgpoints, imgpoints2, rvecs, tvecs = calibrate_camera(angled_view_images)\n",
    "\n",
    "print(\"\\n--- Calibration Results for Angled View Images ---\")\n",
    "print(f\"Reprojection Error: {reprojection_error:.4f}\")\n",
    "print(f\"Distortion Coefficients: {distortion_coeffs}\")\n",
    "print(f\"Distortion Analysis: {analyze_distortion(distortion_coeffs)}\")\n",
    "\n",
    "# all images\n",
    "all_images = []\n",
    "all_images.extend(straight_on_images)\n",
    "all_images.extend(end_of_the_frame_images)\n",
    "all_images.extend(tilted_and_rotated_images)\n",
    "all_images.extend(angled_view_images)\n",
    "intrinsic_matrix, distortion_coeffs, reprojection_error, imgpoints, imgpoints2, rvecs, tvecs = calibrate_camera(all_images)\n",
    "\n",
    "print(\"\\n--- Calibration Results for All Images ---\")\n",
    "print(f\"Reprojection Error: {reprojection_error:.4f}\")\n",
    "print(f\"Distortion Coefficients: {distortion_coeffs}\")\n",
    "print(f\"Distortion Analysis: {analyze_distortion(distortion_coeffs)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbac93f4",
   "metadata": {},
   "source": [
    "# Camera extrinsics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fc15a90",
   "metadata": {},
   "source": [
    "It's the transformation from object world to the camera. Camera extrinsics consist of rotation (R) and translation (t) matrices that define the camera's position and orientation in 3D world coordinates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1551b789",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_scene_with_cameras(points, colors, camera_poses, scale=0.2, imgpoints=None, imgpoints2=None, all_images=None):\n",
    "    \"\"\"Visualize 3D points, camera positions, and reprojection in a single plot with the actual camera image\"\"\"\n",
    "    import plotly.graph_objects as go\n",
    "    from plotly.subplots import make_subplots\n",
    "    import cv2\n",
    "    \n",
    "    # Camera positions in world coordinates\n",
    "    camera_positions = []\n",
    "    camera_rotations = []\n",
    "    \n",
    "    for i, pose in enumerate(camera_poses):\n",
    "        R = pose[:, :3]\n",
    "        t = pose[:, 3]\n",
    "        \n",
    "        # Camera center (C = -R^T * t)\n",
    "        center = -R.T @ t\n",
    "        \n",
    "        camera_positions.append(center)\n",
    "        camera_rotations.append(R)\n",
    "    \n",
    "    # Create figure with subplots - 3D scene on left, camera image on right\n",
    "    fig = make_subplots(\n",
    "        rows=1, cols=2,\n",
    "        column_widths=[0.7, 0.3],\n",
    "        specs=[[{\"type\": \"scene\"}, {\"type\": \"image\"}]],\n",
    "        subplot_titles=[\"3D Scene with Camera and Chessboard\", \"Camera Image\"]\n",
    "    )\n",
    "    \n",
    "    # Add 3D points (chessboard points in world coordinates)\n",
    "    color_str = [f'rgb({int(r*255)},{int(g*255)},{int(b*255)})' for r, g, b in colors]\n",
    "    fig.add_trace(go.Scatter3d(\n",
    "        x=points[:, 0],\n",
    "        y=points[:, 1], \n",
    "        z=points[:, 2],\n",
    "        mode='markers',\n",
    "        marker=dict(\n",
    "            size=3,\n",
    "            color=color_str,\n",
    "            opacity=0.8\n",
    "        ),\n",
    "        name='Chessboard Points'\n",
    "    ), row=1, col=1)\n",
    "    \n",
    "    # Add world coordinate frame (chessboard frame)\n",
    "    axes_length = scale * 2\n",
    "    axes_colors = ['darkred', 'darkgreen', 'darkblue']\n",
    "    axes_names = ['X_world', 'Y_world', 'Z_world']\n",
    "    \n",
    "    # Origin of world coordinates (chessboard origin)\n",
    "    world_origin = np.array([0, 0, 0])\n",
    "    \n",
    "    # Draw world coordinate axes - for chessboard, Z should point UP perpendicular to board\n",
    "    for axis in range(3):\n",
    "        direction = np.zeros(3)\n",
    "        direction[axis] = axes_length\n",
    "        \n",
    "        fig.add_trace(go.Scatter3d(\n",
    "            x=[world_origin[0], world_origin[0] + direction[0]],\n",
    "            y=[world_origin[1], world_origin[1] + direction[1]],\n",
    "            z=[world_origin[2], world_origin[2] + direction[2]],\n",
    "            mode='lines+text',\n",
    "            line=dict(color=axes_colors[axis], width=5),\n",
    "            text=['', axes_names[axis]],\n",
    "            textposition='top center',\n",
    "            showlegend=False\n",
    "        ), row=1, col=1)\n",
    "    \n",
    "    # Add cameras\n",
    "    for i, (center, R) in enumerate(zip(camera_positions, camera_rotations)):\n",
    "        # Camera position\n",
    "        fig.add_trace(go.Scatter3d(\n",
    "            x=[center[0]], \n",
    "            y=[center[1]], \n",
    "            z=[center[2]],\n",
    "            mode='markers+text',\n",
    "            marker=dict(size=10, color='red'),\n",
    "            text=[f'Camera {i+1}'],\n",
    "            name=f'Camera {i+1}'\n",
    "        ), row=1, col=1)\n",
    "        \n",
    "        # Camera coordinate axes - proper camera convention\n",
    "        axes_length = scale * 1.5\n",
    "        axes_colors = ['red', 'green', 'blue']\n",
    "        axes_names = [f'X_cam{i+1}', f'Y_cam{i+1}', f'Z_cam{i+1}']\n",
    "        \n",
    "        # Draw camera axes\n",
    "        for axis in range(3):\n",
    "            # Create unit vector in camera coordinates\n",
    "            axis_dir = np.zeros(3)\n",
    "            axis_dir[axis] = 1\n",
    "            \n",
    "            # Transform to world coordinates using camera rotation\n",
    "            if axis == 2:\n",
    "                # Z-axis points from camera toward scene\n",
    "                world_dir = -R.T @ axis_dir\n",
    "            else:\n",
    "                world_dir = R.T @ axis_dir\n",
    "                \n",
    "            # Scale to requested length\n",
    "            world_dir = world_dir * axes_length\n",
    "            \n",
    "            # Draw the axis\n",
    "            fig.add_trace(go.Scatter3d(\n",
    "                x=[center[0], center[0] + world_dir[0]],\n",
    "                y=[center[1], center[1] + world_dir[1]],\n",
    "                z=[center[2], center[2] + world_dir[2]],\n",
    "                mode='lines+text',\n",
    "                line=dict(color=axes_colors[axis], width=3),\n",
    "                text=['', axes_names[axis]],\n",
    "                textposition='top center',\n",
    "                showlegend=False\n",
    "            ), row=1, col=1)\n",
    "    \n",
    "    # Add detected and reprojected points near the chessboard\n",
    "    if imgpoints is not None and imgpoints2 is not None and len(imgpoints) > 0:\n",
    "        # Get the camera pose for the current camera\n",
    "        R = camera_poses[0][:, :3]\n",
    "        t = camera_poses[0][:, 3]\n",
    "        \n",
    "        # Get intrinsic matrix (assume it's passed in via arguments or global)\n",
    "        # We need to actually access the global variable since we don't have it as a parameter\n",
    "        global intrinsic_matrix\n",
    "        \n",
    "        # Detected points (blue)\n",
    "        if len(imgpoints[0]) > 0:\n",
    "            # Extract 2D image points\n",
    "            img_pts = imgpoints[0].reshape(-1, 2)\n",
    "            \n",
    "            # For each image point, project a ray from camera to chessboard\n",
    "            world_pts_detected = []\n",
    "            for idx, pt in enumerate(img_pts):\n",
    "                # The corresponding 3D point in world coordinates (from original points)\n",
    "                world_pt = points[idx]\n",
    "                \n",
    "                # Create a slightly offset point to visualize detected points\n",
    "                world_pts_detected.append(world_pt + np.array([0, 0, 0.05]))  # Offset in Z\n",
    "            \n",
    "            # Convert to numpy array\n",
    "            world_pts_detected = np.array(world_pts_detected)\n",
    "            \n",
    "            # Add detected points to plot\n",
    "            fig.add_trace(go.Scatter3d(\n",
    "                x=world_pts_detected[:, 0],\n",
    "                y=world_pts_detected[:, 1],\n",
    "                z=world_pts_detected[:, 2],\n",
    "                mode='markers',\n",
    "                marker=dict(\n",
    "                    size=5,\n",
    "                    color='blue',\n",
    "                    symbol='circle'\n",
    "                ),\n",
    "                name='Detected Points (Blue)'\n",
    "            ), row=1, col=1)\n",
    "            \n",
    "            # Connect original points to detected points with lines\n",
    "            for i in range(len(world_pts_detected)):\n",
    "                fig.add_trace(go.Scatter3d(\n",
    "                    x=[points[i, 0], world_pts_detected[i, 0]],\n",
    "                    y=[points[i, 1], world_pts_detected[i, 1]],\n",
    "                    z=[points[i, 2], world_pts_detected[i, 2]],\n",
    "                    mode='lines',\n",
    "                    line=dict(color='blue', width=1),\n",
    "                    showlegend=False\n",
    "                ), row=1, col=1)\n",
    "        \n",
    "        # Reprojected points (red)\n",
    "        if imgpoints2 is not None:\n",
    "            # Handle the case where imgpoints2 is a list\n",
    "            if isinstance(imgpoints2, list):\n",
    "                # Extract the first element if it's a list\n",
    "                imgpoints2_data = imgpoints2[0]\n",
    "            else:\n",
    "                imgpoints2_data = imgpoints2\n",
    "                \n",
    "            # Extract 2D reprojected points\n",
    "            reproj_pts = imgpoints2_data.reshape(-1, 2)\n",
    "            \n",
    "            # For each reprojected point, create a visual point\n",
    "            world_pts_reprojected = []\n",
    "            for idx, pt in enumerate(reproj_pts):\n",
    "                # The corresponding 3D point in world coordinates\n",
    "                world_pt = points[idx]\n",
    "                \n",
    "                # Create a slightly offset point to visualize reprojected points\n",
    "                world_pts_reprojected.append(world_pt + np.array([0, 0, 0.1]))  # Higher offset in Z\n",
    "            \n",
    "            # Convert to numpy array\n",
    "            world_pts_reprojected = np.array(world_pts_reprojected)\n",
    "            \n",
    "            # Add reprojected points to plot\n",
    "            fig.add_trace(go.Scatter3d(\n",
    "                x=world_pts_reprojected[:, 0],\n",
    "                y=world_pts_reprojected[:, 1],\n",
    "                z=world_pts_reprojected[:, 2],\n",
    "                mode='markers',\n",
    "                marker=dict(\n",
    "                    size=5,\n",
    "                    color='red',\n",
    "                    symbol='circle'\n",
    "                ),\n",
    "                name='Reprojected Points (Red)'\n",
    "            ), row=1, col=1)\n",
    "            \n",
    "            # Connect original points to reprojected points with lines\n",
    "            for i in range(len(world_pts_reprojected)):\n",
    "                fig.add_trace(go.Scatter3d(\n",
    "                    x=[points[i, 0], world_pts_reprojected[i, 0]],\n",
    "                    y=[points[i, 1], world_pts_reprojected[i, 1]],\n",
    "                    z=[points[i, 2], world_pts_reprojected[i, 2]],\n",
    "                    mode='lines',\n",
    "                    line=dict(color='red', width=1),\n",
    "                    showlegend=False\n",
    "                ), row=1, col=1)\n",
    "    \n",
    "    # Add legend for coordinate systems\n",
    "    fig.add_trace(go.Scatter3d(\n",
    "        x=[None], y=[None], z=[None],\n",
    "        mode='markers',\n",
    "        marker=dict(size=0),\n",
    "        name='Chessboard frame: dark RGB axes (Z up)',\n",
    "        showlegend=True\n",
    "    ), row=1, col=1)\n",
    "    \n",
    "    fig.add_trace(go.Scatter3d(\n",
    "        x=[None], y=[None], z=[None],\n",
    "        mode='markers',\n",
    "        marker=dict(size=0),\n",
    "        name='Camera frames: bright RGB axes (Z toward scene)',\n",
    "        showlegend=True\n",
    "    ), row=1, col=1)\n",
    "    \n",
    "    # Add the camera image if provided\n",
    "    if all_images is not None and len(all_images) > 0:\n",
    "        # Read the image and convert it to RGB\n",
    "        img = cv2.imread(all_images[0])\n",
    "        if img is not None:\n",
    "            # Resize the image to reduce memory usage\n",
    "            max_dim = 400  # Maximum dimension\n",
    "            h, w = img.shape[:2]\n",
    "            if h > max_dim or w > max_dim:\n",
    "                # Calculate the resize factor\n",
    "                factor = max_dim / max(h, w)\n",
    "                img = cv2.resize(img, (int(w * factor), int(h * factor)))\n",
    "            \n",
    "            img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            \n",
    "            # Add image to the right subplot\n",
    "            fig.add_trace(\n",
    "                go.Image(\n",
    "                    z=img_rgb,\n",
    "                    name=\"Camera Image\"\n",
    "                ),\n",
    "                row=1, col=2\n",
    "            )\n",
    "    \n",
    "    # Setup layout with better camera position\n",
    "    fig.update_layout(\n",
    "        scene=dict(\n",
    "            xaxis_title='X',\n",
    "            yaxis_title='Y',\n",
    "            zaxis_title='Z',\n",
    "            # Set initial camera viewpoint for better visualization\n",
    "            camera=dict(\n",
    "                eye=dict(x=2.5, y=2.5, z=1.5),  # Viewpoint further back to see everything\n",
    "                up=dict(x=0, y=0, z=1)  # Z-up view\n",
    "            ),\n",
    "            aspectmode='data'\n",
    "        ),\n",
    "        width=1200,  # Wider for better view\n",
    "        height=700,\n",
    "        title=\"Camera Calibration Visualization with Reprojection Errors\",\n",
    "        legend=dict(\n",
    "            orientation=\"h\",\n",
    "            yanchor=\"bottom\",\n",
    "            y=1.02,\n",
    "            xanchor=\"center\", \n",
    "            x=0.5\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    # Update image subplot\n",
    "    fig.update_xaxes(showticklabels=False, row=1, col=2)\n",
    "    fig.update_yaxes(showticklabels=False, row=1, col=2)\n",
    "    \n",
    "    return fig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c7f9e60",
   "metadata": {},
   "source": [
    "### Camera Extrinsics Visualization: Understanding Projection Errors\n",
    "\n",
    "The visualizations in the next cell demonstrate how lens distortion and inaccuracies in the projection matrix contribute to errors in image reconstruction. Each visualization shows:\n",
    "\n",
    "1. **3D Chessboard Points**: The original points in world coordinates\n",
    "2. **Camera Position**: The estimated position and orientation of the camera\n",
    "3. **Detected Points (Blue)**: The actual points detected in the image\n",
    "4. **Reprojected Points (Red)**: Where the camera model predicts these points should appear\n",
    "\n",
    "The difference between blue and red points represents the reprojection error, which quantifies the accuracy of our camera model. Higher errors indicate:\n",
    "\n",
    "- Uncorrected lens distortions\n",
    "- Imprecise camera calibration\n",
    "- Limitations in the mathematical model\n",
    "\n",
    "These visualizations help us understand why perfect 3D reconstruction from 2D images is challenging and why multiple views and robust algorithms are necessary for accurate results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a10006d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "all_images = []\n",
    "all_images.extend(straight_on_images)\n",
    "all_images.extend(end_of_the_frame_images)\n",
    "all_images.extend(tilted_and_rotated_images)\n",
    "all_images.extend(angled_view_images)\n",
    "intrinsic_matrix, distortion_coeffs, reprojection_error, imgpoints, imgpoints2, rvecs, tvecs = calibrate_camera(all_images)\n",
    "\n",
    "# Prepare camera poses for visualization\n",
    "camera_poses = []\n",
    "for r, t in zip(rvecs, tvecs):\n",
    "    # Convert rotation vector to rotation matrix\n",
    "    R, _ = cv2.Rodrigues(r)\n",
    "    # Create full camera pose [R|t]\n",
    "    pose = np.hstack((R, t))\n",
    "    camera_poses.append(pose)\n",
    "\n",
    "# Create 3D chessboard points\n",
    "objp = np.zeros((6*9, 3), np.float32)\n",
    "objp[:, :2] = np.mgrid[0:9, 0:6].T.reshape(-1, 2)\n",
    "colors = np.ones((6*9, 3)) * 0.5  # Neutral gray color for all points\n",
    "\n",
    "# Visualize each camera separately with its reprojection errors\n",
    "for i in range(len(camera_poses)):\n",
    "    # Create a single-camera visualization\n",
    "    camera_pose = [camera_poses[i]]\n",
    "    \n",
    "    # Get current image points for this camera\n",
    "    current_imgpoints = [imgpoints[i]]\n",
    "    \n",
    "    # IMPORTANT: Don't wrap imgpoints2 in a list - pass it directly\n",
    "    current_imgpoints2 = imgpoints2  # Don't wrap in list\n",
    "    \n",
    "    # Create visualization\n",
    "    fig = visualize_scene_with_cameras(\n",
    "        objp, \n",
    "        colors, \n",
    "        camera_pose, \n",
    "        scale=1.0, \n",
    "        imgpoints=current_imgpoints, \n",
    "        imgpoints2=current_imgpoints2,  # Pass without wrapping in list\n",
    "        all_images=[all_images[i]],\n",
    "    )\n",
    "    \n",
    "    # Show visualization with camera name\n",
    "    fig.update_layout(title=f\"Camera {i+1}: {os.path.basename(all_images[i])}\")\n",
    "    fig.show()\n",
    "    \n",
    "    # Calculate mean reprojection error for this camera\n",
    "    error = cv2.norm(imgpoints[i], imgpoints2, cv2.NORM_L2) / len(imgpoints2)\n",
    "    print(f\"Camera {i+1}: Mean reprojection error = {error:.4f} pixels\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
